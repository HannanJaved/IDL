{"cells":[{"cell_type":"markdown","metadata":{"id":"9QYQO2Z1dwxb"},"source":["# Assignment 11: Whatâ€™s Wrong With Our Data? - Kai Ponel & Hannan Mahadik\n"]},{"cell_type":"markdown","metadata":{"id":"ifPYAVPadzYc"},"source":["# Happy new Year 2023! \n","(Finally, I'm first)"]},{"cell_type":"markdown","metadata":{"id":"7YRHz7zFd4la"},"source":["# Data Stuff "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLr8AWU56gtq"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras import layers\n","from keras.layers import RandomFlip, RandomRotation, Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout, InputLayer\n","from keras.models import Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28181,"status":"ok","timestamp":1673185515657,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-60},"id":"cPTOy42ydnpU","outputId":"650fdf51-a3a9-47b4-d594-20dfbde4ae78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY6YVzHQ6eaV"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/ColabNotebooks/IDL_Hannan_Kai/Task 11/data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Gpdhkyk6_Sg"},"outputs":[],"source":["### Unzipping files\n","\n","# !unzip data/cifar_attempts.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rw7XxNqw_siJ"},"outputs":[],"source":["### Load all the data into memory (If this causes mem issues, load it one at-a-time)\n","\n","label_def = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n","\n","data = []\n","for i in range(1,5):\n","  data.append(np.load(\"data{}.npz\".format(i)))"]},{"cell_type":"markdown","source":["# Some inspections"],"metadata":{"id":"HRDzk5kCTpRG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18752,"status":"ok","timestamp":1673185539108,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-60},"id":"LOBX9QWCDVFn","outputId":"b4c6d499-d6ec-41cb-9ab1-d9e32ac935b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Available data : ['test_imgs', 'test_lbls', 'train_imgs', 'train_lbls', 'val_imgs', 'val_lbls']\n","Checking dataset 0:\n","Available Train images: 36004\n","Available Test images: 10000\n","Available Val images: 3996\n","Checking dataset 1:\n","Available Train images: 50000\n","Available Test images: 10000\n","Available Val images: 5000\n","Checking dataset 2:\n","Available Train images: 45000\n","Available Test images: 10000\n","Available Val images: 5000\n","Checking dataset 3:\n","Available Train images: 45000\n","Available Test images: 10000\n","Available Val images: 5000\n"]}],"source":["### Check the size of the dataset \n","print(\"Available data : {}\".format(dir(data[0].f)))\n","for index, dataset in enumerate(data):\n","  print(\"Checking dataset {}:\".format(i))\n","  print(\"Available Train images: {}\".format(len(dataset[\"train_imgs\"])))\n","  print(\"Available Test images: {}\".format(len(dataset[\"test_imgs\"])))\n","  print(\"Available Val images: {}\".format(len(dataset[\"val_imgs\"])))"]},{"cell_type":"code","source":["### Check the distribution of the labels within the sets:\n","import collections\n","for index, dataset in enumerate(data):\n","   print(\"dataset {}\".format(index))\n","   for subset in [\"train\", \"test\", \"val\"]:\n","     count_map = {}\n","     for a in dataset[\"{}_lbls\".format(subset)]:\n","       if a not in count_map:\n","         count_map[a]=1\n","       else:\n","         count_map[a]+=1\n","     print(\"{}: {}\".format(subset, collections.OrderedDict(sorted(count_map.items()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-d9dwt776DF","executionInfo":{"status":"ok","timestamp":1673191090135,"user_tz":-60,"elapsed":554,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"}},"outputId":"50ae0af7-d022-4cb2-e441-d77d6dc12aec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset 0\n","train: OrderedDict([(0, 4507), (1, 4512), (2, 4521), (4, 4525), (5, 4471), (6, 4512), (8, 4468), (9, 4488)])\n","test: OrderedDict([(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)])\n","val: OrderedDict([(0, 493), (1, 488), (2, 479), (4, 475), (5, 529), (6, 488), (8, 532), (9, 512)])\n","dataset 1\n","train: OrderedDict([(0, 5000), (1, 5000), (2, 5000), (3, 5000), (4, 5000), (5, 5000), (6, 5000), (7, 5000), (8, 5000), (9, 5000)])\n","test: OrderedDict([(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)])\n","val: OrderedDict([(0, 493), (1, 488), (2, 479), (3, 519), (4, 475), (5, 529), (6, 488), (7, 485), (8, 532), (9, 512)])\n","dataset 2\n","train: OrderedDict([(0, 4507), (1, 4512), (2, 4521), (3, 4481), (4, 4525), (5, 4471), (6, 4512), (7, 4515), (8, 4468), (9, 4488)])\n","test: OrderedDict([(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)])\n","val: OrderedDict([(0, 493), (1, 488), (2, 479), (3, 519), (4, 475), (5, 529), (6, 488), (7, 485), (8, 532), (9, 512)])\n","dataset 3\n","train: OrderedDict([(0, 4500), (1, 4500), (2, 4500), (3, 4500), (4, 4500), (5, 4500), (6, 4500), (7, 4500), (8, 4500), (9, 4500)])\n","test: OrderedDict([(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)])\n","val: OrderedDict([(0, 500), (1, 500), (2, 500), (3, 500), (4, 500), (5, 500), (6, 500), (7, 500), (8, 500), (9, 500)])\n"]}]},{"cell_type":"code","source":["### Plot results of col*rows images for normal images\n","columns = 4\n","rows = 4\n","\n","def print_some_images(images, labels):\n","  fig = plt.figure(figsize=(7,7))\n","  for i in range(1, columns*rows + 1):\n","    img = tf.cast(images[i+20-1] * 255, tf.int32)\n","    fig.add_subplot(rows, columns, i)\n","    plt.title(label_def[labels[i+20-1]])\n","    plt.imshow(img)\n","  plt.show()"],"metadata":{"id":"8Tq89K2kUgua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index, dataset in enumerate(data):\n","  print(\"Images of the dataset: {}\".format(index))\n","  for subset in [\"train\", \"test\", \"val\"]:\n","    print(\"{}-set:\".format(subset))\n","    print_some_images(images=dataset[\"{}_imgs\".format(subset)], labels=dataset[\"{}_lbls\".format(subset)])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SA7U2vzUvkl7TGSkw_vpyxK1PsAgFRnA"},"id":"759ztHjxWedG","executionInfo":{"status":"ok","timestamp":1673190528576,"user_tz":-60,"elapsed":22220,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"}},"outputId":"1741eff0-2fde-4b11-f3f5-40f0689e0b26"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"MkkqhxKODGqU"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"FEDMBM45BMmz"},"source":["## Model Definition\n","(Copied from the adversarial Training task)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSwCdLSXBRbk"},"outputs":[],"source":["### Hyperparameters\n","initializer = tf.keras.initializers.HeNormal()\n","regularizer = tf.keras.regularizers.L2(1e-4)\n","\n","### Define the early stopping callback \n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","  monitor=\"val_loss\",\n","  patience=3,  \n","  restore_best_weights=True  \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHZWoWMFFYNT"},"outputs":[],"source":["### A simple CNN model for classifying the CIFAR10 images\n","model_base = [\n","  # InputLayer(32,32,3),\n","  RandomFlip(\"horizontal_and_vertical\"),\n","  RandomRotation(0.2),\n","  InputLayer(32,32,3),\n","  Conv2D(32, 3, activation='relu', kernel_regularizer=regularizer, kernel_initializer=initializer),\n","  MaxPooling2D((2, 2)),\n","  Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=regularizer, kernel_initializer=initializer),\n","  MaxPooling2D((2, 2)),\n","  Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=regularizer, kernel_initializer=initializer),\n","  MaxPooling2D((2, 2)),\n","  Flatten(),\n","  Dense(128, activation='relu'),\n","  Dense(10, activation='softmax')\n","]"]},{"cell_type":"markdown","metadata":{"id":"u4STJuG-DEyO"},"source":["## Model Training (Iteratively!)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2pp6vevFy0O","executionInfo":{"status":"ok","timestamp":1673187985342,"user_tz":-60,"elapsed":1478439,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"}},"outputId":"9fd83573-60fb-4e5a-bce9-65be45b85fbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model trained on dataset 1\n","Epoch 1/25\n","256/256 [==============================] - 18s 67ms/step - loss: 0.8563 - sparse_categorical_accuracy: 0.7188 - val_loss: 1.7508 - val_sparse_categorical_accuracy: 0.5817\n","Epoch 2/25\n","256/256 [==============================] - 18s 70ms/step - loss: 0.8442 - sparse_categorical_accuracy: 0.7243 - val_loss: 1.8509 - val_sparse_categorical_accuracy: 0.5791\n","Epoch 3/25\n","256/256 [==============================] - 18s 69ms/step - loss: 0.8300 - sparse_categorical_accuracy: 0.7328 - val_loss: 2.0968 - val_sparse_categorical_accuracy: 0.5838\n","Epoch 4/25\n","256/256 [==============================] - 14s 57ms/step - loss: 0.8290 - sparse_categorical_accuracy: 0.7283 - val_loss: 2.2899 - val_sparse_categorical_accuracy: 0.5368\n","Epoch 5/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.8369 - sparse_categorical_accuracy: 0.7246 - val_loss: 2.3198 - val_sparse_categorical_accuracy: 0.5701\n","Epoch 6/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.8182 - sparse_categorical_accuracy: 0.7341 - val_loss: 2.1835 - val_sparse_categorical_accuracy: 0.5849\n","Epoch 7/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.8315 - sparse_categorical_accuracy: 0.7297 - val_loss: 2.4294 - val_sparse_categorical_accuracy: 0.5730\n","Epoch 8/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.8077 - sparse_categorical_accuracy: 0.7343 - val_loss: 2.7258 - val_sparse_categorical_accuracy: 0.5706\n","Epoch 9/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.8197 - sparse_categorical_accuracy: 0.7351 - val_loss: 2.6322 - val_sparse_categorical_accuracy: 0.5787\n","Epoch 10/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.8138 - sparse_categorical_accuracy: 0.7365 - val_loss: 2.6374 - val_sparse_categorical_accuracy: 0.5761\n","Epoch 11/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.8170 - sparse_categorical_accuracy: 0.7340 - val_loss: 2.5454 - val_sparse_categorical_accuracy: 0.5647\n","Epoch 12/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.8131 - sparse_categorical_accuracy: 0.7384 - val_loss: 2.7094 - val_sparse_categorical_accuracy: 0.5830\n","Epoch 13/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.8186 - sparse_categorical_accuracy: 0.7343 - val_loss: 2.6301 - val_sparse_categorical_accuracy: 0.5869\n","Epoch 14/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.8082 - sparse_categorical_accuracy: 0.7347 - val_loss: 2.8616 - val_sparse_categorical_accuracy: 0.5804\n","Epoch 15/25\n","256/256 [==============================] - 16s 62ms/step - loss: 0.7954 - sparse_categorical_accuracy: 0.7395 - val_loss: 2.9219 - val_sparse_categorical_accuracy: 0.5589\n","Epoch 16/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.8012 - sparse_categorical_accuracy: 0.7384 - val_loss: 2.9177 - val_sparse_categorical_accuracy: 0.5761\n","Epoch 17/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.7913 - sparse_categorical_accuracy: 0.7421 - val_loss: 2.7469 - val_sparse_categorical_accuracy: 0.5814\n","Epoch 18/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.7953 - sparse_categorical_accuracy: 0.7440 - val_loss: 2.9686 - val_sparse_categorical_accuracy: 0.5662\n","Epoch 19/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.7970 - sparse_categorical_accuracy: 0.7422 - val_loss: 3.1326 - val_sparse_categorical_accuracy: 0.5609\n","Epoch 20/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.8020 - sparse_categorical_accuracy: 0.7399 - val_loss: 2.9704 - val_sparse_categorical_accuracy: 0.5899\n","Epoch 21/25\n","256/256 [==============================] - 13s 53ms/step - loss: 0.7843 - sparse_categorical_accuracy: 0.7499 - val_loss: 2.9405 - val_sparse_categorical_accuracy: 0.5909\n","Epoch 22/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.7884 - sparse_categorical_accuracy: 0.7415 - val_loss: 3.0097 - val_sparse_categorical_accuracy: 0.5782\n","Epoch 23/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.7812 - sparse_categorical_accuracy: 0.7464 - val_loss: 3.2841 - val_sparse_categorical_accuracy: 0.5680\n","Epoch 24/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.7868 - sparse_categorical_accuracy: 0.7466 - val_loss: 2.9966 - val_sparse_categorical_accuracy: 0.5917\n","Epoch 25/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.7812 - sparse_categorical_accuracy: 0.7460 - val_loss: 3.4202 - val_sparse_categorical_accuracy: 0.5601\n","63/63 [==============================] - 0s 4ms/step - loss: 0.9168 - sparse_categorical_accuracy: 0.7207\n","Accuracy on the 0. validation set: 0.7207207083702087\n","Model trained on dataset 2\n","Epoch 1/25\n","256/256 [==============================] - 15s 54ms/step - loss: 1.2417 - sparse_categorical_accuracy: 0.6139 - val_loss: 1.2418 - val_sparse_categorical_accuracy: 0.6112\n","Epoch 2/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0576 - sparse_categorical_accuracy: 0.6591 - val_loss: 1.1070 - val_sparse_categorical_accuracy: 0.6497\n","Epoch 3/25\n","256/256 [==============================] - 14s 53ms/step - loss: 1.0659 - sparse_categorical_accuracy: 0.6518 - val_loss: 1.0578 - val_sparse_categorical_accuracy: 0.6667\n","Epoch 4/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0202 - sparse_categorical_accuracy: 0.6645 - val_loss: 1.0740 - val_sparse_categorical_accuracy: 0.6654\n","Epoch 5/25\n","256/256 [==============================] - 15s 60ms/step - loss: 1.0170 - sparse_categorical_accuracy: 0.6720 - val_loss: 1.1306 - val_sparse_categorical_accuracy: 0.6386\n","Epoch 6/25\n","256/256 [==============================] - 14s 54ms/step - loss: 1.0406 - sparse_categorical_accuracy: 0.6581 - val_loss: 1.0487 - val_sparse_categorical_accuracy: 0.6624\n","Epoch 7/25\n","256/256 [==============================] - 14s 53ms/step - loss: 1.0019 - sparse_categorical_accuracy: 0.6749 - val_loss: 1.0959 - val_sparse_categorical_accuracy: 0.6567\n","Epoch 8/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0107 - sparse_categorical_accuracy: 0.6733 - val_loss: 1.0884 - val_sparse_categorical_accuracy: 0.6633\n","Epoch 9/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0217 - sparse_categorical_accuracy: 0.6694 - val_loss: 1.0696 - val_sparse_categorical_accuracy: 0.6652\n","Epoch 10/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9915 - sparse_categorical_accuracy: 0.6790 - val_loss: 1.1065 - val_sparse_categorical_accuracy: 0.6526\n","Epoch 11/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.9948 - sparse_categorical_accuracy: 0.6769 - val_loss: 1.1186 - val_sparse_categorical_accuracy: 0.6487\n","Epoch 12/25\n","256/256 [==============================] - 13s 53ms/step - loss: 1.0215 - sparse_categorical_accuracy: 0.6689 - val_loss: 1.0538 - val_sparse_categorical_accuracy: 0.6692\n","Epoch 13/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9900 - sparse_categorical_accuracy: 0.6807 - val_loss: 1.1611 - val_sparse_categorical_accuracy: 0.6445\n","Epoch 14/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0013 - sparse_categorical_accuracy: 0.6729 - val_loss: 1.0773 - val_sparse_categorical_accuracy: 0.6613\n","Epoch 15/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9997 - sparse_categorical_accuracy: 0.6744 - val_loss: 1.0588 - val_sparse_categorical_accuracy: 0.6663\n","Epoch 16/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9843 - sparse_categorical_accuracy: 0.6798 - val_loss: 1.0526 - val_sparse_categorical_accuracy: 0.6672\n","Epoch 17/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9957 - sparse_categorical_accuracy: 0.6732 - val_loss: 1.0652 - val_sparse_categorical_accuracy: 0.6618\n","Epoch 18/25\n","256/256 [==============================] - 13s 52ms/step - loss: 1.0045 - sparse_categorical_accuracy: 0.6753 - val_loss: 1.0453 - val_sparse_categorical_accuracy: 0.6667\n","Epoch 19/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9741 - sparse_categorical_accuracy: 0.6827 - val_loss: 1.0745 - val_sparse_categorical_accuracy: 0.6610\n","Epoch 20/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9920 - sparse_categorical_accuracy: 0.6776 - val_loss: 1.1641 - val_sparse_categorical_accuracy: 0.6345\n","Epoch 21/25\n","256/256 [==============================] - 15s 59ms/step - loss: 0.9810 - sparse_categorical_accuracy: 0.6801 - val_loss: 1.0708 - val_sparse_categorical_accuracy: 0.6624\n","Epoch 22/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9788 - sparse_categorical_accuracy: 0.6815 - val_loss: 1.0472 - val_sparse_categorical_accuracy: 0.6680\n","Epoch 23/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9726 - sparse_categorical_accuracy: 0.6846 - val_loss: 1.0863 - val_sparse_categorical_accuracy: 0.6599\n","Epoch 24/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9805 - sparse_categorical_accuracy: 0.6854 - val_loss: 1.0565 - val_sparse_categorical_accuracy: 0.6657\n","Epoch 25/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9717 - sparse_categorical_accuracy: 0.6868 - val_loss: 1.0521 - val_sparse_categorical_accuracy: 0.6711\n","79/79 [==============================] - 0s 4ms/step - loss: 0.9601 - sparse_categorical_accuracy: 0.6932\n","Accuracy on the 1. validation set: 0.6931999921798706\n","Model trained on dataset 3\n","Epoch 1/25\n","256/256 [==============================] - 15s 53ms/step - loss: 0.9722 - sparse_categorical_accuracy: 0.6853 - val_loss: 6.1143 - val_sparse_categorical_accuracy: 0.2387\n","Epoch 2/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9676 - sparse_categorical_accuracy: 0.6873 - val_loss: 6.8006 - val_sparse_categorical_accuracy: 0.2276\n","Epoch 3/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.9774 - sparse_categorical_accuracy: 0.6821 - val_loss: 5.7814 - val_sparse_categorical_accuracy: 0.2519\n","Epoch 4/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.9763 - sparse_categorical_accuracy: 0.6805 - val_loss: 3.9960 - val_sparse_categorical_accuracy: 0.2761\n","Epoch 5/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9577 - sparse_categorical_accuracy: 0.6931 - val_loss: 5.9796 - val_sparse_categorical_accuracy: 0.2185\n","Epoch 6/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.9782 - sparse_categorical_accuracy: 0.6844 - val_loss: 4.7766 - val_sparse_categorical_accuracy: 0.2518\n","Epoch 7/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9718 - sparse_categorical_accuracy: 0.6896 - val_loss: 5.6825 - val_sparse_categorical_accuracy: 0.2422\n","Epoch 8/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.9720 - sparse_categorical_accuracy: 0.6821 - val_loss: 4.9888 - val_sparse_categorical_accuracy: 0.2533\n","Epoch 9/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.9619 - sparse_categorical_accuracy: 0.6899 - val_loss: 8.7575 - val_sparse_categorical_accuracy: 0.2093\n","Epoch 10/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.9606 - sparse_categorical_accuracy: 0.6891 - val_loss: 7.9517 - val_sparse_categorical_accuracy: 0.2084\n","Epoch 11/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.9778 - sparse_categorical_accuracy: 0.6849 - val_loss: 6.3370 - val_sparse_categorical_accuracy: 0.2296\n","Epoch 12/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9613 - sparse_categorical_accuracy: 0.6935 - val_loss: 5.0630 - val_sparse_categorical_accuracy: 0.2413\n","Epoch 13/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9508 - sparse_categorical_accuracy: 0.6970 - val_loss: 8.6260 - val_sparse_categorical_accuracy: 0.2003\n","Epoch 14/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9692 - sparse_categorical_accuracy: 0.6862 - val_loss: 5.4468 - val_sparse_categorical_accuracy: 0.2327\n","Epoch 15/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9562 - sparse_categorical_accuracy: 0.6909 - val_loss: 6.1457 - val_sparse_categorical_accuracy: 0.2127\n","Epoch 16/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9579 - sparse_categorical_accuracy: 0.6921 - val_loss: 7.6594 - val_sparse_categorical_accuracy: 0.2077\n","Epoch 17/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9571 - sparse_categorical_accuracy: 0.6948 - val_loss: 6.1266 - val_sparse_categorical_accuracy: 0.2229\n","Epoch 18/25\n","256/256 [==============================] - 13s 53ms/step - loss: 0.9614 - sparse_categorical_accuracy: 0.6923 - val_loss: 6.1977 - val_sparse_categorical_accuracy: 0.2372\n","Epoch 19/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9498 - sparse_categorical_accuracy: 0.6954 - val_loss: 5.2935 - val_sparse_categorical_accuracy: 0.2335\n","Epoch 20/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9402 - sparse_categorical_accuracy: 0.6945 - val_loss: 6.1105 - val_sparse_categorical_accuracy: 0.2339\n","Epoch 21/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.9551 - sparse_categorical_accuracy: 0.6985 - val_loss: 6.3516 - val_sparse_categorical_accuracy: 0.2338\n","Epoch 22/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.9681 - sparse_categorical_accuracy: 0.6847 - val_loss: 6.6066 - val_sparse_categorical_accuracy: 0.2200\n","Epoch 23/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.9445 - sparse_categorical_accuracy: 0.6953 - val_loss: 7.2148 - val_sparse_categorical_accuracy: 0.2132\n","Epoch 24/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.9286 - sparse_categorical_accuracy: 0.7047 - val_loss: 6.6677 - val_sparse_categorical_accuracy: 0.2190\n","Epoch 25/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.9525 - sparse_categorical_accuracy: 0.6963 - val_loss: 6.0700 - val_sparse_categorical_accuracy: 0.2228\n","79/79 [==============================] - 0s 4ms/step - loss: 1.0231 - sparse_categorical_accuracy: 0.6760\n","Accuracy on the 2. validation set: 0.6759999990463257\n","Model trained on dataset 4\n","Epoch 1/25\n","256/256 [==============================] - 15s 53ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9982 - val_loss: 2.0429 - val_sparse_categorical_accuracy: 0.5463\n","Epoch 2/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.0613 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.2075 - val_sparse_categorical_accuracy: 0.5363\n","Epoch 3/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0476 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.4187 - val_sparse_categorical_accuracy: 0.5143\n","Epoch 4/25\n","256/256 [==============================] - 13s 53ms/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9405 - val_sparse_categorical_accuracy: 0.4742\n","Epoch 5/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.0289 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7637 - val_sparse_categorical_accuracy: 0.4098\n","Epoch 6/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.0229 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5098 - val_sparse_categorical_accuracy: 0.3694\n","Epoch 7/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0183 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.1734 - val_sparse_categorical_accuracy: 0.3305\n","Epoch 8/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.0149 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.6004 - val_sparse_categorical_accuracy: 0.3068\n","Epoch 9/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.0122 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.3228 - val_sparse_categorical_accuracy: 0.2704\n","Epoch 10/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.4330 - sparse_categorical_accuracy: 0.9505 - val_loss: 7.1039 - val_sparse_categorical_accuracy: 0.1777\n","Epoch 11/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0184 - sparse_categorical_accuracy: 1.0000 - val_loss: 8.2989 - val_sparse_categorical_accuracy: 0.1770\n","Epoch 12/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0170 - sparse_categorical_accuracy: 1.0000 - val_loss: 8.8573 - val_sparse_categorical_accuracy: 0.1766\n","Epoch 13/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.0165 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.2300 - val_sparse_categorical_accuracy: 0.1765\n","Epoch 14/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0161 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.4673 - val_sparse_categorical_accuracy: 0.1764\n","Epoch 15/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0158 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.6974 - val_sparse_categorical_accuracy: 0.1765\n","Epoch 16/25\n","256/256 [==============================] - 15s 59ms/step - loss: 0.0155 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.9102 - val_sparse_categorical_accuracy: 0.1764\n","Epoch 17/25\n","256/256 [==============================] - 13s 52ms/step - loss: 0.0152 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.0722 - val_sparse_categorical_accuracy: 0.1763\n","Epoch 18/25\n","256/256 [==============================] - 13s 53ms/step - loss: 0.0148 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.1941 - val_sparse_categorical_accuracy: 0.1761\n","Epoch 19/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0144 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3596 - val_sparse_categorical_accuracy: 0.1758\n","Epoch 20/25\n","256/256 [==============================] - 14s 54ms/step - loss: 0.0141 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4629 - val_sparse_categorical_accuracy: 0.1763\n","Epoch 21/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.0137 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5780 - val_sparse_categorical_accuracy: 0.1768\n","Epoch 22/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0132 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6765 - val_sparse_categorical_accuracy: 0.1768\n","Epoch 23/25\n","256/256 [==============================] - 14s 53ms/step - loss: 0.0128 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.7487 - val_sparse_categorical_accuracy: 0.1767\n","Epoch 24/25\n","256/256 [==============================] - 14s 56ms/step - loss: 0.0124 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.8505 - val_sparse_categorical_accuracy: 0.1757\n","Epoch 25/25\n","256/256 [==============================] - 14s 55ms/step - loss: 0.0119 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9315 - val_sparse_categorical_accuracy: 0.1758\n","79/79 [==============================] - 0s 4ms/step - loss: 0.0117 - sparse_categorical_accuracy: 1.0000\n","Accuracy on the 3. validation set: 1.0\n"]}],"source":["models = []\n","# Loop over all the datasets and train equivalent models after one another\n","for index, dataset in enumerate(data):\n","  print(\"Model trained on dataset {}\".format(index+1))\n","  # Load / Create the model\n","  model = Sequential(model_base)\n","  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n","\n","  train_ds = tf.data.Dataset.from_tensor_slices((dataset[\"train_imgs\"], dataset[\"train_lbls\"])).batch(64).repeat()\n","  test_ds = tf.data.Dataset.from_tensor_slices((dataset[\"test_imgs\"], dataset[\"test_lbls\"])).batch(64)\n","  val_ds = tf.data.Dataset.from_tensor_slices((dataset[\"val_imgs\"], dataset[\"val_lbls\"])).batch(64)\n","\n","\n","  # Train the model\n","  # Let's disable early_stopping and set the epochs fixed to 20 to see what happens...\n","  # model.fit(train_ds, epochs=100, steps_per_epoch=256, validation_data=test_ds, callbacks=[early_stopping])\n","  model.fit(train_ds, epochs=25, steps_per_epoch=256, validation_data=test_ds)\n","  # Store the model\n","  models.append(model)\n","  print(\"Accuracy on the {}. validation set: {}\".format(index, model.evaluate(val_ds)[1]))\n"]},{"cell_type":"code","source":["### Some evaluation stats on the test set:\n","# Note: Storing the models in an list does not appear to work... The test_acc is kinda fishy which does not happen immediately after training. \n","for index, model in enumerate(models):\n","  current_data = data[index]\n","  test_images = current_data[\"test_imgs\"]\n","  test_labels = current_data[\"test_lbls\"]\n","\n","  test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(64)\n","  print(\"Loss/Test accuracy on {}. dataset: {}\".format(index+1, model.evaluate(test_ds)))"],"metadata":{"id":"MTkPdpwT34hI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summary\n","\n","## Dataset 1: \n","train and val set do not contain examples of labels 3 and 7, but test set does <br>\n","*This may happen in the real world because of different sets originate from different enviorments or due to human error.*\n","## Dataset 2:\n","Seems alright at first glance - Val set is not perfectly balanced but this also holds for 0 and 2. <br>\n","Validation Set is a subset of the training set. \n","*This may happen in the real world due to normal inaccuracies? Perhaps I missed something here*\n","## Dataset 3:\n","- Pixel values appear to be \"invalid\" on the test data, but are alright on the train/val data. This causes issues when trying to maximize the test acc.\n","- Train and val set is not perfectly balanced as all things should be (+/- ~20-50 images). This might be impactful when measuring performance since the val set is way smaller. <br>\n","\n","*This may happen in the real world due to messaurment errors when creating the subsets in different enviorments / at different times*\n","\n","## Dataset 4: \n","- Images are included in multiple subsets and are not mutually exclusive.\n","- Train and val set only contain very few images, but these ones are repeated very often. <br>\n"," \n","*This may happen in the real world due to basic human error or unsuited enviorments when collecting the data (?)*\n","\n","## General notes:\n","- Images are shared across the datasets (but this is wanted, I assume)\n","- Set 3&4 have the same amount of images in the subsets, while 2 contains 5k more train images and 1 about 10k less (which is probably caused by the missing classes in ds 1)\n"],"metadata":{"id":"isuolOOZ-tIu"}},{"cell_type":"markdown","source":["For Dataset 3, using BN will improve the model performance (before every conv.)\n","It is not noise, it was a form of Normalisation. "],"metadata":{"id":"2iy229gXGFnb"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}